{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-12T08:45:24.286531Z","iopub.execute_input":"2022-06-12T08:45:24.287024Z","iopub.status.idle":"2022-06-12T08:45:24.294703Z","shell.execute_reply.started":"2022-06-12T08:45:24.286955Z","shell.execute_reply":"2022-06-12T08:45:24.293856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/2022-ml-quiz2-p4/sample_submit.csv')\ntest = pd.read_csv('../input/2022-ml-quiz2-p4/test.csv')\ntrain = pd.read_csv('../input/2022-ml-quiz2-p4/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.303127Z","iopub.execute_input":"2022-06-12T08:45:24.303583Z","iopub.status.idle":"2022-06-12T08:45:24.335966Z","shell.execute_reply.started":"2022-06-12T08:45:24.303542Z","shell.execute_reply":"2022-06-12T08:45:24.334666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX = train.drop(['Unnamed: 0', '일자', '중식계'], axis=1)\ntrainY = train['중식계']\ntestX = test.drop(['Unnamed: 0', '일자'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.381003Z","iopub.execute_input":"2022-06-12T08:45:24.381943Z","iopub.status.idle":"2022-06-12T08:45:24.390319Z","shell.execute_reply.started":"2022-06-12T08:45:24.381879Z","shell.execute_reply":"2022-06-12T08:45:24.389127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrainX['요일'] = le.fit_transform(trainX['요일'])\ntestX['요일'] = le.transform(testX['요일'])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.405248Z","iopub.execute_input":"2022-06-12T08:45:24.406114Z","iopub.status.idle":"2022-06-12T08:45:24.414471Z","shell.execute_reply.started":"2022-06-12T08:45:24.406065Z","shell.execute_reply":"2022-06-12T08:45:24.413657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.416561Z","iopub.execute_input":"2022-06-12T08:45:24.41754Z","iopub.status.idle":"2022-06-12T08:45:24.446488Z","shell.execute_reply.started":"2022-06-12T08:45:24.417488Z","shell.execute_reply":"2022-06-12T08:45:24.445632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breakfast_train = [x for x in trainX['조식메뉴']]\nlunch_train = [x for x in trainX['중식메뉴']]\ndinner_train = [x for x in trainX['석식메뉴']]\n\nbreakfast_test = [x for x in testX['조식메뉴']]\nlunch_test = [x for x in testX['중식메뉴']]\ndinner_test = [x for x in testX['석식메뉴']]","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.483707Z","iopub.execute_input":"2022-06-12T08:45:24.484512Z","iopub.status.idle":"2022-06-12T08:45:24.493196Z","shell.execute_reply.started":"2022-06-12T08:45:24.484458Z","shell.execute_reply":"2022-06-12T08:45:24.49198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\n\nbreakfast_feature = vectorizer.fit(breakfast_train + breakfast_test)\nbreakfast_train = vectorizer.transform(breakfast_train).toarray().flatten()\nbreakfast_test = vectorizer.transform(breakfast_test).toarray().flatten()\n\nlunch_feature = vectorizer.fit(lunch_train + lunch_test)\nlunch_train = vectorizer.transform(lunch_train).toarray().flatten()\nlunch_test = vectorizer.transform(lunch_test).toarray().flatten()\n\ndinner_feature = vectorizer.fit(dinner_train + dinner_test)\ndinner_train = vectorizer.transform(dinner_train).toarray().flatten()\ndinner_test = vectorizer.transform(dinner_test).toarray().flatten()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.616952Z","iopub.execute_input":"2022-06-12T08:45:24.617394Z","iopub.status.idle":"2022-06-12T08:45:24.77422Z","shell.execute_reply.started":"2022-06-12T08:45:24.617356Z","shell.execute_reply":"2022-06-12T08:45:24.773049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX['조식메뉴'] = pd.DataFrame(breakfast_train)\ntrainX['중식메뉴'] = pd.DataFrame(lunch_train)\ntrainX['석식메뉴'] = pd.DataFrame(dinner_train)\n\ntestX['조식메뉴'] = pd.DataFrame(breakfast_test)\ntestX['중식메뉴'] = pd.DataFrame(lunch_test)\ntestX['석식메뉴'] = pd.DataFrame(dinner_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.79068Z","iopub.execute_input":"2022-06-12T08:45:24.7912Z","iopub.status.idle":"2022-06-12T08:45:24.806635Z","shell.execute_reply.started":"2022-06-12T08:45:24.791156Z","shell.execute_reply":"2022-06-12T08:45:24.805412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()\nmodel.fit(trainX, trainY)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:45:24.808243Z","iopub.execute_input":"2022-06-12T08:45:24.809506Z","iopub.status.idle":"2022-06-12T08:45:25.122614Z","shell.execute_reply.started":"2022-06-12T08:45:24.809465Z","shell.execute_reply":"2022-06-12T08:45:25.121579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['중식계'] = model.predict(testX)\nsubmit.to_csv('result.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:46:38.518521Z","iopub.execute_input":"2022-06-12T08:46:38.519016Z","iopub.status.idle":"2022-06-12T08:46:38.547736Z","shell.execute_reply.started":"2022-06-12T08:46:38.518975Z","shell.execute_reply":"2022-06-12T08:46:38.546672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}