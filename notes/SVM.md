# SVM

# Linear SVM : ì„ í˜• SVM

### **SVM : Supprot Vector Machine**

íŒ¨í„´ ì¸ì‹, ìë£Œë¶„ì„ì„ ìœ„í•œ ì§€ë„ í•™ìŠµ ëª¨ë¸

ë¶„ë¥˜ì™€ íšŒê·€ ë¬¸ì œì— ì‚¬ìš© ( ì£¼ë¡œ ë¶„ë¥˜ ë¬¸ì œ ì‚¬ìš©)

ë‘ ì¹´í…Œê³ ë¦¬ ì¤‘ ì–´ëŠ í•˜ë‚˜ì— ì†í•œ ë°ì´í„°ì˜ ì§‘í•©ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì£¼ì–´ì§„ ë°ì´í„° ì§‘í• ì„ ë°”íƒ•ìœ¼ë¡œ í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì–´ëŠ ì¹´í…Œê³ ë¦¬ì— ì†í•  ì§€ íŒë‹¨í•˜ëŠ” ë¹„-í™•ë¥ ì  ì´ì§„ ì„ í˜• ë¶„ë¥˜ ëª¨ë¸

ì»¤ë„ íŠ¸ë¦­ì„ í™œìš©í•˜ì—¬ ë¹„ì„ í˜• ë¶„ë¥˜ ë¬¸ì œì—ë„ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. 

### **í•™ìŠµ ë°©í–¥ : ë§ˆì§„(Margin)ì˜ ìµœëŒ€í™”**

ê²½ê³„ ê²°ê³„ (hyperplane)ëŠ” ì£¼ë³€ ë°ì´í„°ì™€ì˜ ê±°ë¦¬ê°€ ìµœëŒ€ê°€ ë˜ì–´ì•¼ í•¨.

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%201.png)

### ìš©ì–´

âœ” ê²°ì • ê²½ê³„ (Hyperplane) : ì„œë¡œ ë‹¤ë¥¸ í¬ë˜ìŠ¤ë¥¼ ì™„ë²½í•˜ê²Œ ë¶„ë¥˜í•˜ëŠ” ê¸°ì¤€

âœ” ì„œí¬íŠ¸ ë²¡í„° (Support vector) : ê²°ì • ê²½ê³„ì„ ì— ê°€ì¥ ê°€ê¹Œì´ì— ìˆëŠ” ê° í´ë˜ìŠ¤ì˜ ë°ì´í„° 

âœ” ë§ˆì§„ (Margin) : ì–´ë–¤ ë°ì´í„°ë„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ì˜ì—­, ì„œí¬íŠ¸ ë²¡í„°ì™€ ì§êµí•˜ëŠ” ì§ì„ ê³¼ì˜ ê±°ë¦¬ 

### ê²°ì • ê²½ê³„ (Hyperplane)

ë°ì´í„° ì„ë² ë”© ê³µê°„ë³´ë‹¤ 1ì°¨ì› ë‚®ì€ ë¶€ë¶„ê³µê°„

ì˜ˆ) 2ì°¨ì› ë°ì´í„° ê³µê°„ì˜ ê²°ì • ê²½ê³„ : ì§ì„ 

3ì°¨ì› ë°ì´í„° ê³µê°„ì˜ ê²°ì • ê²½ê³„ : í‰ë©´

4ì°¨ì› ì´ìƒ ë°ì´í„° ê³µê°„ì˜ ê²°ì • ê²½ê³„ : ì´ˆí‰ë©´

### ìˆ˜í•™ì  í‘œí˜„

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%202.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%203.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%204.png)

### Hard Margin SVMì˜ ëª©ì  í•¨ìˆ˜

âœ” ë§ˆì§„ì˜ ìµœëŒ€í™” 

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%205.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%206.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%207.png)

### (W, b, Î±)ê°€ Langrangian dual problemì˜ ìµœì í•´ê°€ ë˜ê¸° ìœ„í•œ ì¡°ê±´

âœ” KKT (Karush-Kuhn-Tucker) Conditions

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%208.png)

### Hard margin SVM vs Soft Margin SVM

âœ” Hard Margin SVM : ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥í•œ ë¬¸ì œ

âœ” Soft Margin SVM : ì„ í˜• ë¶„ë¦¬ ë¶ˆê°€ëŠ¥í•œ ë¬¸ì œ - í•™ìŠµë°ì´í„°ì˜ ì—ëŸ¬ê°€ 0ì´ ë˜ë„ë¡ ì™„ë²½í•˜ê²Œ ë‚˜ëˆ„ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥ â†’ ì—ëŸ¬ë¥¼ í—ˆìš©í•˜ì !

â– suppor vector : ë§ˆì§„ì„ ê²°ì • 

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%209.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2010.png)

### Soft Margin SVMì˜ ëª©ì í•¨ìˆ˜

: ì—ëŸ¬(penalty term)ì„ í—ˆìš©í•˜ë©´ì„œ Marginì„ ìµœëŒ€í™” 

âœ” Cë¥¼ í†µí•´ ì—ëŸ¬ì˜ í—ˆìš©ì •ë„ë¥¼ ì¡°ì ˆ

 â†’ Cê°€ í¬ë©´  í•™ìŠµ ì—ëŸ¬ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ í—ˆìš©í•˜ì§€ ì•ŠìŒ (Overfitting) â†’ ë§ˆì§„ì´ ì‘ì•„ì§

 â†’ Cê°€ ì‘ìœ¼ë©´  í•™ìŠµ ì—ëŸ¬ë¥¼ ìƒëŒ€ì ìœ¼ë¡œ í—ˆìš© (Underfitting) â†’ ë§ˆì§„ì´ ì»¤ì§

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2011.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2012.png)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2013.png)

### Hard Marginê³¼ Soft Margin

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2014.png)

# Nonlinear SVM : ë¹„ì„ í˜• SVM

### ì„ í˜• SVM vs ë¹„ì„ í˜• SVM

âœ” ì„ í˜• SVM : Hard margin SVM, Soft Margin SVM

âœ” ë¹„ì„ í˜• SVM : Kernel SVM

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2015.png)

### ë¹„ì„ í˜• SVM

ë°ì´í„°ë¥¼ ì„ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ì°¨ì›ì„ ë†’ì´ëŠ” ë°©ë²•ì„ ì‚¬ìš©

Feature Map(Î¦) ì„ í†µí•´ ì°¨ì›ì„ ë†’ì„. ì¦‰, x ëŒ€ì‹  Î¦(X)ë¥¼ ì‚¬ìš©

ì»¤ë„ : Feature Mapì˜ ë‚´ì   Î¦(X)â€¢Î¦(Y)

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2016.png)

### ë¹„ì„ í˜• SVMì˜ í•´ë²•

SVM ëª¨ë¸ì„ Original Spaceê°€ ì•„ë‹Œ Feature Spaceì—ì„œ í•™ìŠµ ( X â†’ Î¦(X) )

Transfer : Original space - Nonlinear decision boundary â†’  Feature space - linear decision boundary

ê³ ì°¨ì› Feature spaceì—ì„œëŠ” ë¶„ë¥˜ê°€ ë” ì‰¬ìš¸ ìˆ˜ ìˆìŒì„ ì…ì¦ 

ğŸ‘‡ ê³ ì°¨ì› Feature spaceë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë°©ë²• 

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2017.png)

### ë¹„ì„ í˜• SVMì˜ ëª©ì í•¨ìˆ˜

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2018.png)

### Kernel Mappingì˜ ì˜ˆ

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2019.png)

âœ” ì»¤ë„ ì‚¬ìš©ì„ í†µí•´ ëª…ì‹œì (explicitly)ìœ¼ë¡œ Î¦(X), Î¦(Y)ë¥¼ ê°ê° ê³„ì‚°í•˜ì§€ ì•Šê³  ì•”ë¬µì (implicitly)ìœ¼ë¡œ     <Î¦(X),Î¦(Y)>ë¥¼ ë°”ë¡œ ê³„ì‚°í•˜ì—¬ ì—°ì‚° íš¨ìœ¨ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2020.png)

### Kernel Functionì˜ ì˜ˆ

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2021.png)

â› ì•„ì§ ì–´ë–¤ kernelì˜ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜í•˜ë‹¤ ì´ëŸ°ê²ƒì€ ì—†ë‹¤. 

### ë¹„ì„ í˜• SVMì˜ ì˜ˆì‹œ

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2022.png)

: ì„ í˜• ë¶„ë¥˜ê°€ ë¶ˆê°€ëŠ¥ í•˜ë¯€ë¡œ Kernel ì ìš©

: Low degree polynomial kernel function ì‚¬ìš© - K(x,y) = (xy+1)Â²

: Tuning parameter - C=100

### ë¹„ì„ í˜• SVMì˜ Î± ê³„ì‚°

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2023.png)

Î±â‚‚, Î±â‚„, Î±â‚… : hyperplaneì„ ê²°ì •ì§“ëŠ” support vector

- Î±_i â‰  0 â†’ Î±_i>0, x_i â†’ SV

- Î±_i = 0 â†’ x_i â‰  SV 

### ë¹„ì„ í˜• SVMì˜ Î± ê³„ì‚° â†’ b ê³„ì‚° â†’ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2024.png)

á¼± âˆˆ { Î±â‚‚, Î±â‚„, Î±â‚… }

f(x) ì— ê°’ ëŒ€ì… í›„ â†’ f(x) > 0 ì´ë©´ 1 class / f(x) < 0 ì´ë©´ -1 class

### ë¹„ì„ í˜• SVMì˜ kernel ì„ ì •ë²•

 SVM kernelì„ ê²°ì •í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ë¬¸ì œì´ë‹¤. (ì •í•´ì§„ ê¸°ì¤€ì´ ì—†ìœ¼ë¯€ë¡œ ì‹¤í—˜ì ìœ¼ë¡œ ê²°ì •í•´ì•¼í•¨.)

ì‚¬ìš©í•˜ëŠ” kernelì— ë”°ë¼ feature spaceì˜ íŠ¹ì§•ì´ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— ë°ì´í„°ì˜ íŠ¹ì„±ì— ë§ëŠ” kernelì„ ê²°ì •í•˜ëŠ” ê²ƒì€ ì¤‘ìš”í•˜ë‹¤. 

 â†’ ì¼ë°˜ì ìœ¼ë¡œ RBF Kernel, Sigmoid Kernel, Low Degree Polynomial Kernel(4ì°¨ë¯¸ë§Œ) ë“±ì´ ì£¼ë¡œ ì‚¬ìš©.

âœ” ì»¤ë„ì— ë”°ë¥¸ ë¶„ë¥˜ ê²°ê³¼

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2025.png)

test errorë¥¼ í™•ì¸í•´ ë³´ë©´ ì˜¤ë¥¸ìª½ì˜ RBFê°€ test errorê°€ ì‘ìœ¼ë¯€ë¡œ ì„±ëŠ¥ì´ ë” ì¢‹ë‹¤. 

# SVM ë‹¤ê³„ì¸µ ë¶„ë¥˜ : Multi Classification

âœ” í•˜ë‚˜-ë‚˜ë¨¸ì§€ ë°©ë²• (One-vs-Rest)

: ì´í•­ ë¶„ë¥˜ ê°’(hypothesis function)ì´ ê°€ì¥ í° ê°’ì„ ê·¸ë£¹ìœ¼ë¡œ í• ë‹¹ 

  â†’ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê°’ìœ¼ë¡œ class ê²°ì •

  â†’ ë³¸ì¸ë§Œ 1, ë‚˜ë¨¸ì§€ëŠ” -1ë¡œ í†µì¼ â‡’ ë¶„ë¥˜ê¸°ê°€ classì˜ ìˆ˜ë§Œí¼ í•„ìš” !

âœ” í•˜ë‚˜-í•˜ë‚˜ ë°©ë²• (One-vs-One)

: ì£¼ì–´ì§„ íŠ¹ì„± ìë£Œì— ëŒ€í•´ ê°€ì¥ ë§ì´ í• ë‹¹ëœ ê·¸ë£¹ìœ¼ë¡œ í• ë‹¹ - voting ë°©ì‹

  â†’ nCâ‚‚ ê°œì˜ ë¶„ë¥˜ê¸°ê°€ í•„ìš” !

![Untitled](SVM%2028f82a60dafa48f39c18bff8fc244a69/Untitled%2026.png)

## ğŸ’»ì‹¤ìŠµí•´ë³´ê¸°

### ì •ë¦¬

**SVM ë¶„ë¥˜ê¸°**

 : ì´ì§„ë¶„ë¥˜ê¸°, deep learning ì´ì „ ì•„ì£¼ ë„ë¦¬ ì‚¬ìš©ë˜ë˜ ê¸°ë²•

âœ” ì„ í˜• SVM - Hard Margin SVM : ì™„ì „íˆ ë¶„ë¥˜ ê°€ëŠ¥

                      - Soft Margin SVM : errorê°€ ë§ì€ ê²½ìš° errorë¥¼ í—ˆìš©

âœ” ë¹„ì„ í˜• SVM : ì°¨ì›ì„ ë†’ì—¬ì„œ í•´ê²°,  X â†’ Î¦(X) â‡’ ì»¤ë„ì„ ë„ì…

**parameter**

âœ” C : Soft Margin SVMì—ì„œ ì‚¬ìš© - ì–¼ë§ˆë‚˜ errorë¥¼ í—ˆìš©í•  ê²ƒì¸ê°€?

âœ” kernel : linear, poly, RBF, sigmoid

âœ” ovo, ovr : ë‹¤ì¤‘ ë¶„ë¥˜ê¸°ë¡œ í™•ì¥ì‹œí‚¬ ë•Œ ì‚¬ìš©

### SVCì™€ SVR ì¶”í›„ ìˆ˜ì • ì˜ˆì •.. ğŸ˜¥