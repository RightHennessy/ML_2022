# Preprocessing : ë°ì´í„° ì „ì²˜ë¦¬

### ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •

1) ë°ì´í„° ì‹¤ìˆ˜í™”: ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê°’ìœ¼ë¡œì˜ ë³€í™˜

2) ë¶ˆì™„ì „í•œ ë°ì´í„° ì œê±°: NULL, NA, NAN ê°’ì˜ ì œê±°

3) ì¡ìŒ ì„ì¸ ë°ì´í„° ì œê±°

: ê°€ê²© ë°ì´í„°ì— ìˆëŠ” (-) ê°’ ì œê±° - ê°€ê²©ì´ -100ì›ì¸ ê²½ìš°
: ì—°ë ¹ ë°ì´í„° ì¤‘ ê³¼ë„í•˜ê²Œ í° ê°’ ì œê±° - ë‚˜ì´ ê°’ìœ¼ë¡œ 200, 300, 400 ë“±ì˜ ê°’ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°

4) ëª¨ìˆœëœ ë°ì´í„° ì œê±° : ë‚¨ì„± ë°ì´í„° ì¤‘ ì£¼ë¯¼ë²ˆí˜¸ê°€ â€˜2â€™ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°

5) ë¶ˆê· í˜• ë°ì´í„° í•´ê²° : ê³¼ì†Œí‘œì§‘(undersampling), ê³¼ëŒ€í‘œì§‘(oversampling)

### ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì£¼ìš” ê¸°ë²•

1ï¸âƒ£ ë°ì´í„° ì‹¤ìˆ˜í™” (Data Vectorization)

ë²”ì£¼í˜• ìë£Œ, í…ìŠ¤íŠ¸ ìë£Œ, ì´ë¯¸ì§€ ìë£Œ ë“±ì„ ì‹¤ìˆ˜ë¡œ êµ¬ì„±ëœ í˜•íƒœë¡œ ì „í™˜í•˜ëŠ” ê²ƒ

2ï¸âƒ£ ë°ì´í„° ì •ì œ (Data Cleaning)

ì—†ëŠ” ë°ì´í„°ëŠ” ì±„ìš°ê³ , ì¡ìŒ ë°ì´í„°ëŠ” ì œê±°í•˜ê³ , ëª¨ìˆœ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥¸ ë°ì´í„°ë¡œ êµì •í•˜ëŠ” ê²ƒ

3ï¸âƒ£ ë°ì´í„° í†µí•© (Data Integration)

ì—¬ëŸ¬ ê°œì˜ ë°ì´í„° íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê³¼ì •

4ï¸âƒ£ ë°ì´í„° ì¶•ì†Œ (Data Reduction)

ë°ì´í„°ê°€ ê³¼ë„í•˜ê²Œ í° ê²½ìš°, ë¶„ì„ ë° í•™ìŠµì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  ë¹„íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì— ë°ì´í„°ì˜ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜(Sampling), ë°ì´í„° ì°¨ì›ì„ ì¶•ì†Œí•˜ëŠ” ì‘ì—…

5ï¸âƒ£ ë°ì´í„° ë³€í™˜ (Data Transformation)

ë°ì´í„°ë¥¼ ì •ê·œí™” í•˜ê±°ë‚˜, ë¡œê·¸ë¥¼ ì”Œìš°ê±°ë‚˜, í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ì‚¬ìš©í•˜ê±°ë‚˜, ì‚¬ëŒ ë‚˜ì´ ë“±ì„ 10ëŒ€, 20ëŒ€, 30ëŒ€ ë“±ìœ¼ë¡œ êµ¬ê°„ í™” í•˜ëŠ” ì‘ì—…

6ï¸âƒ£ ë°ì´í„° ê· í˜• (Data Balancing)

íŠ¹ì • í´ë˜ìŠ¤ì˜ ê´€ì¸¡ì¹˜ê°€ ë‹¤ë¥¸ í´ë˜ìŠ¤ì— ë¹„í•´ ë§¤ìš° ë‚®ì„ ê²½ìš° ìƒ˜í”Œë§ì„ í†µí•´
í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ë§ì¶”ëŠ” ì‘ì—…

### 1ï¸âƒ£ ë°ì´í„° ì‹¤ìˆ˜í™”

âœ” ìë£Œì˜ ìœ í˜•

ì—°ì†í˜• ìë£Œ (Continuous data), ë²”ì£¼í˜• ìë£Œ (Categorical data), í…ìŠ¤íŠ¸ ìë£Œ (Text data)

**ë²”ì£¼í˜• ìë£Œì˜ ì‹¤ìˆ˜í™”** 

âœ” One-hot encoding ì„ ì´ìš©í•œ ë°ì´í„° ì‹¤ìˆ˜í™”

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled.png)

âœ” Scikit-learnì˜ `DictVectorizer` í•¨ìˆ˜

ë²”ì£¼í˜• ìë£Œì˜ ì‹¤ìˆ˜í™” í•˜ëŠ” í•¨ìˆ˜

Input argument : ë””í´íŠ¸ ì˜µì…˜ Sparse=True â†’ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê¸° ìœ„í•´ì„œëŠ” Falseë¡œ ì„¤ì •

```python
# ë²”ì£¼í˜• ìë£Œì˜ ìˆ˜ëŸ‰í™” 
x = [{'city':'seoul', 'temp':10.0}, {'city':'Dubai', 'temp':33.5}, {'city':'LA', 'temp':20.0}]
x

from sklearn.feature_extraction import DictVectorizer
vec = DictVectorizer(sparse=False)
vec.fit_transform(x)
```

[ {'city':'seoul', 'temp':10.0}, 
  {'city':'Dubai', 'temp':33.5}, 
  {'city':'LA', 'temp':20.0} ]

array( [ [ 0. , 0. , 1. , 10. ],
            [1. , 0. , 0. , 33.5 ],
            [ 0. , 1. , 0. , 20. ] ] )

âœ” í¬ì†Œí–‰ë ¬(Sparse Matrix)

í–‰ë ¬ì˜ ê°’ì´ ëŒ€ë¶€ë¶„ 0ì¸ ê²½ìš°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²½ìš°

 â†’ ë¶ˆí•„ìš”í•œ 0 ê°’ìœ¼ë¡œ ì¸í•´ ë©”ëª¨ë¦¬ ë‚­ë¹„ê°€ ì‹¬í•˜ê³  í–‰ë ¬ì˜ í¬ê¸°ê°€ ì»¤ì„œ ì—°ì‚°ì‹œ ì‹œê°„ë„ ë§ì´ ì†Œëª¨

 â†’ COOí‘œí˜„ì‹ê³¼ CSRí‘œí˜„ì‹ì„ í†µí•´ ë¬¸ì œ í•´ê²° ê°€ëŠ¥

ğŸ‘‰ CSR í‘œí˜„ì‹ (Compressed Sparse Row)

 : COOí˜•ì‹ì— ë¹„í•´ ë©”ëª¨ë¦¬ê°€ ì ê²Œ ë“¤ê³  ë¹ ë¥¸ ì—°ì‚°ì´ ê°€ëŠ¥í•¨

```python
velc = DictVectorizer(sparse=True)  #ë©”ëª¨ë¦¬ë¥¼ ì¤„ì´ê¸° ìœ„í•´ 
x1 = vecl.fit_transform(x)
x1
```

<3x4 sparse matrix of type â€˜<class â€˜numpy.float64â€™>â€™ with 6 stored elements in Compressed Sparse Row format>

**í…ìŠ¤íŠ¸ ìë£Œì˜ ì‹¤ìˆ˜í™”** 

âœ” ë‹¨ì–´ì˜ ì¶œí˜„ íšŸìˆ˜ë¥¼ ì´ìš©í•œ ë°ì´í„° ì‹¤ìˆ˜í™”

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%201.png)

```python
# í…ìŠ¤íŠ¸ ìë£Œì˜ ìˆ˜ëŸ‰í™” 
text = ['ë–´ë‹¤ ë–´ë‹¤ ë¹„í–‰ê¸° ë‚ ì•„ë¼ ë‚ ì•„ë¼',
				'ë†’ì´ ë†’ì´ ë‚ ì•„ë¼ ìš°ë¦¬ ë¹„í–‰ê¸°',
			  'ë‚´ê°€ ë§Œë“  ë¹„í–‰ê¸° ë‚ ì•„ë¼ ë‚ ì•„ë¼',
			  'ë©€ë¦¬ ë©€ë¦¬ ë‚ ì•„ë¼ ìš°ë¦¬ ë¹„í–‰ê¸°']
text
```

[ 'ë–´ë‹¤ ë–´ë‹¤ ë¹„í–‰ê¸° ë‚ ì•„ë¼ ë‚ ì•„ë¼',
  â€˜ë†’ì´ ë†’ì´ ë‚ ì•„ë¼ ìš°ë¦¬ ë¹„í–‰ê¸°â€™,
  â€˜ë‚´ê°€ ë§Œë“  ë¹„í–‰ê¸° ë‚ ì•„ë¼ ë‚ ì•„ë¼â€™,
  â€˜ë©€ë¦¬ ë©€ë¦¬ ë‚ ì•„ë¼ ìš°ë¦¬ ë¹„í–‰ê¸°â€™]

```python
from sklearn.feature_extraction.text import CountVectorizer
vec2 = CountVectorizer()
t = vec2.fit_transform(text).toarray() #sparse=Trueë¥¼ í’€ê³  textë¥¼ ìˆ˜ëŸ‰í™” ë°°ì—´ ìë£Œë¡œ ë³€í™˜

import pandas as pd
t1 = pd.DataFrame(t, columns=vec2.get_feature_means())
t1
```

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%202.png)

BUT ì¶œí˜„ íšŸìˆ˜ê°€ ì •ë³´ì˜ ì–‘ê³¼ ë¹„ë¡€í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. â†’ TF-IDF ê¸°ë²•ì„ ì´ìš©

TF-IDF(Term Frequency Inverse Document Frequency)

 : ìì£¼ ë“±ì¥í•˜ì—¬ ë¶„ì„ì— ì˜ë¯¸ë¥¼ ê°–ì§€ ëª»í•˜ëŠ” ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ë‚®ì¶”ëŠ” ê¸°ë²• (ì˜ˆ) The, a ë“±ì˜ ê´€ì‚¬

â†’ ê°€ì¤‘ì¹˜ ì¬ê³„ì‚°, ë†’ì€ ë¹ˆë„ì— ë‚®ì€ ê°€ì¤‘ì¹˜, ë‚®ì€ ë¹ˆë„ì— ë†’ì€ ê°€ì¤‘ì¹˜

```python
from sklearn.feature_extraction.text import TfidVectorizer
tfid = TfidVectorizer()
x2 = tfid.fit_transform(text).toarray()
x3 = pd.DataFrame(x2, columns = tfid.get_feature_names())
x3
```

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%203.png)

### 2ï¸âƒ£ ë°ì´í„° ì •ì œ

âœ” ê²°ì¸¡ ë°ì´í„° ì±„ìš°ê¸°

ê²°ì¸¡ ë°ì´í„° : np.nan, npNaN, None

â†’ í‰ê· (mean), ì¤‘ìœ„ìˆ˜(median), ìµœë¹ˆìˆ˜(most frequent value)ë¡œ ëŒ€ì²˜í•˜ëŠ” ê¸°ë²• ì‚¬ìš©

```python
# ê²°ì¸¡ìë£Œ ëŒ€ì²´
x_miss = np.array([[1,2,3,None], [5,np.NAN,7,8], [None,10,11,12], [13,np.nan,15,16]])

from sklearn.impute import SimpleImputer
im = Imputer(strategy='mean') # ì—´(ì„¸ë¡œê¸°ì¤€)ì˜ í‰ê· ê°’ìœ¼ë¡œ null ê°’ ëŒ€ì²´
im.git_transfer(x_miss)
```

`impruter()`  ì…ë ¥ ì¸ìë¡œ í‰ê· , ì¤‘ìœ„ìˆ˜, ìµœë¹ˆìˆ˜ ì„ íƒ ê°€ëŠ¥í•˜ë‹¤. 

### 3ï¸âƒ£ ë°ì´í„° í†µí•©

ì—¬ëŸ¬ê°œì˜ ë°ì´í„° íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê³¼ì • : pandasì˜ `merge()`  ì‚¬ìš©

`.dtypes` ë‚˜ `.unique()`  ë¡œ ìë£Œ íƒ€ì…ì„ í™•ì¸í•´ ë³´ì !

### 5ï¸âƒ£ ë°ì´í„° ë³€í™˜

âœ” í•„ìš”ì„±

ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ê°€ ê°€ì§„ íŠ¹ì„±(Feature)ë“¤ì„ ë¹„êµí•˜ì—¬ ë°ì´í„° íŒ¨í„´ì„ ì°¾ëŠ”ë‹¤.

â†’ ë°ì´í„°ê°€ ê°€ì§„ íŠ¹ì„± ê°„ ìŠ¤ì¼€ì¼ ì°¨ì´ê°€ ì‹¬í•˜ë©´ íŒ¨í„´ì„ ì°¾ëŠ”ë° ë¬¸ì œê°€ ë°œìƒí•¨

âœ” ë°©ë²•

1) í‘œì¤€í™” : Standardization

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%204.png)

2) ì •ê·œí™” : Nomarlization

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%205.png)

â­ ì •ê·œí™”ê°€ í‘œì¤€í™”ë³´ë‹¤ ìœ ìš©í•˜ë‹¤. 
     ë‹¨, ë°ì´í„° íŠ¹ì„±ì´ bell-shape ì´ê±°ë‚˜ ì´ìƒì¹˜ê°€ìˆì„ ê²½ìš°ì—ëŠ” í‘œì¤€í™”ê°€ ìœ ìš©í•¨

### 6ï¸âƒ£ë°ì´í„° ê· í˜•

âœ” ë°ì´í„° ë¶ˆê· í˜•ì´ë€?

ë¨¸ì‹ ëŸ¬ë‹ì˜ ëª©ì ì´ ë¶„ë¥˜ ì¼ ë•Œ, íŠ¹ì • í´ë˜ìŠ¤ì˜ ê´€ì¸¡ì¹˜ê°€ ë‹¤ë¥¸ í´ë˜ìŠ¤ì— ë¹„í•´ ë§¤ìš° ë‚®ê²Œ ë‚˜íƒ€ë‚˜ë©´ ì´ëŸ¬í•œ ìë£Œë¥¼ ë¶ˆê· í˜•ìë£Œë¼ê³  í•œë‹¤.

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%206.png)

âœ”ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ ê¸°ë²•

ì¢Œ : ê³¼ëŒ€í‘œì§‘(oversampling), ìš° : ê³¼ì†Œí‘œì§‘(undersampling)

â†’ ì¼ë°˜ì ìœ¼ë¡œ ê³¼ì†Œí‘œì§‘ë³´ë‹¤ ê³¼ëŒ€í‘œì§‘ì´ í†µê³„ì ìœ¼ë¡œ ìœ ìš©í•˜ë‹¤.

â†’ ì˜ì‚¬ê²°ì •ë‚˜ë¬´(decision tree)ì™€ ì•™ìƒë¸”(ensemble)ì€ ìƒëŒ€ì ìœ¼ë¡œ ë¶ˆê· í˜•ìë£Œì— ê°•ì¸í•œ íŠ¹ì„±ì„ ë³´ì„

âœ” ê³¼ì†Œí‘œì§‘(undersampling)

ë‹¤ìˆ˜í´ë˜ìŠ¤ì˜ í‘œë³¸ì„ ì„ìœ¼ë¡œ í•™ìŠµë°ì´í„°ë¡œë¶€í„° ì œê±°í•˜ëŠ” ê²ƒ

âœ” ê³¼ëŒ€í‘œì§‘(oversampling)

ì†Œìˆ˜í´ë˜ìŠ¤ì˜ í‘œë³¸ì„ ë³µì œí•˜ì—¬ ì´ë¥¼ í•™ìŠµë°ì´í„°ì— ì¶”ê°€í•˜ëŠ” ê²ƒ

ëŒ€í‘œì ì¸ ë°©ë²•ë¡  : SMOTE(Synthetic minority oversampling technique)
                             ADASYN(adaptive synthetic sampling method)

```python
import imblearn.over_sampling import SMOTE, ADASYN

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_transform(X, y)

ada = ADASYN(random_state=0)
X_syn, y_syn = ada.fit_transform(X, y)

import imblearn.under_sampling import NearMiss
undersample = NearMiss(version=3, n_neighbors_ver3=3)
X_Under, y_Under = undersample.fit_transform(X, y)
```

![Untitled](Preprocessing%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20cfdb705028624e4ab6d62c815e655c1d/Untitled%207.png)